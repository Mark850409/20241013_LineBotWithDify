# ã€è‡ªå‹•åŒ–çˆ¬èŸ²ã€‘äººå·¥æ™ºæ…§å·¥ä½œåŠ-å¨›æ¨‚æ–°èåŠ©æ‰‹-å¯¦ä½œæµç¨‹

## 1. ç°¡ä»‹

å¦‚ä½•å°‡çˆ¬èŸ²çš„è³‡æ–™å»ºç«‹æˆçŸ¥è­˜åº«ä¸¦ä¸²æ¥`LLMæ¨¡å‹`æœ€å¾Œéƒ¨ç½²åˆ°`LINEBOT`

## 2. ç›®éŒ„

- [ã€è‡ªå‹•åŒ–çˆ¬èŸ²ã€‘äººå·¥æ™ºæ…§å·¥ä½œåŠ-å¨›æ¨‚æ–°èåŠ©æ‰‹-å¯¦ä½œæµç¨‹](#è‡ªå‹•åŒ–çˆ¬èŸ²äººå·¥æ™ºæ…§å·¥ä½œåŠ-å¨›æ¨‚æ–°èåŠ©æ‰‹-å¯¦ä½œæµç¨‹)
  - [1. ç°¡ä»‹](#1-ç°¡ä»‹)
  - [2. ç›®éŒ„](#2-ç›®éŒ„)
  - [3. æ“ä½œæ­¥é©Ÿ](#3-æ“ä½œæ­¥é©Ÿ)
    - [3.1. ä½¿ç”¨dockerå®‰è£dify](#31-ä½¿ç”¨dockerå®‰è£dify)
    - [3.2. difyåŸºç¤é…ç½®èˆ‡è¨­å®š](#32-difyåŸºç¤é…ç½®èˆ‡è¨­å®š)
      - [3.2.1. è¨­å®š`dify`ç®¡ç†å“¡å¸³è™Ÿ](#321-è¨­å®šdifyç®¡ç†å“¡å¸³è™Ÿ)
      - [3.2.2. è¨­å®š`dify`èªè¨€èˆ‡æ™‚å€](#322-è¨­å®šdifyèªè¨€èˆ‡æ™‚å€)
      - [3.2.3. è¨­å®š`æ¨¡å‹ä¾›æ‡‰å•†`](#323-è¨­å®šæ¨¡å‹ä¾›æ‡‰å•†)
    - [3.3. å»ºç«‹`dify`æ–°èå°åŠ©æ‰‹æ‡‰ç”¨](#33-å»ºç«‹difyæ–°èå°åŠ©æ‰‹æ‡‰ç”¨)
      - [3.3.1. å»ºç«‹ç©ºç™½æ‡‰ç”¨\&ç›¸é—œè¨­å®š](#331-å»ºç«‹ç©ºç™½æ‡‰ç”¨ç›¸é—œè¨­å®š)
    - [3.4. pythonçˆ¬èŸ²ç¨‹å¼æ’°å¯«\&difyçŸ¥è­˜åº«APIä¸²æ¥](#34-pythonçˆ¬èŸ²ç¨‹å¼æ’°å¯«difyçŸ¥è­˜åº«apiä¸²æ¥)
      - [3.4.1. yahooå¥‡æ‘©å¨›æ¨‚æ–°èçˆ¬èŸ²ç¨‹å¼ç¢¼](#341-yahooå¥‡æ‘©å¨›æ¨‚æ–°èçˆ¬èŸ²ç¨‹å¼ç¢¼)
      - [3.4.2. difyçŸ¥è­˜åº«APIä¸²æ¥ç¯„ä¾‹](#342-difyçŸ¥è­˜åº«apiä¸²æ¥ç¯„ä¾‹)
    - [3.5. `LINEBOT`èˆ‡`difyçŸ¥è­˜åº«`é€²è¡Œä¸²æ¥](#35-linebotèˆ‡difyçŸ¥è­˜åº«é€²è¡Œä¸²æ¥)
      - [3.5.1. `LINEBOT`èˆ‡\`difyåƒæ•¸è¨­å®š](#351-linebotèˆ‡difyåƒæ•¸è¨­å®š)
      - [3.5.2. LINEBOT WEBHOOK CALLBACKç¨‹å¼](#352-linebot-webhook-callbackç¨‹å¼)
      - [3.5.3. LINEBOT ç›¸é—œäº‹ä»¶é‚è¼¯è™•ç†](#353-linebot-ç›¸é—œäº‹ä»¶é‚è¼¯è™•ç†)
      - [3.5.4. LINEBOT ä¸»ç¨‹å¼é‚è¼¯è™•ç†(è² è²¬æ¥æ”¶ä½¿ç”¨å‚³ééä¾†çš„è¨Šæ¯èˆ‡å›æ‡‰)](#354-linebot-ä¸»ç¨‹å¼é‚è¼¯è™•ç†è² è²¬æ¥æ”¶ä½¿ç”¨å‚³ééä¾†çš„è¨Šæ¯èˆ‡å›æ‡‰)
      - [3.5.5. ä½¿ç”¨`python flask`å•Ÿå‹•`server`](#355-ä½¿ç”¨python-flaskå•Ÿå‹•server)
    - [éƒ¨ç½²`LINEBOT`åˆ°`docker`](#éƒ¨ç½²linebotåˆ°docker)
      - [æ’°å¯«dockerfile](#æ’°å¯«dockerfile)
      - [æ’°å¯«docker-compose.yml](#æ’°å¯«docker-composeyml)
      - [éƒ¨ç½²åˆ°docker](#éƒ¨ç½²åˆ°docker)


## 3. æ“ä½œæ­¥é©Ÿ

### 3.1. ä½¿ç”¨dockerå®‰è£dify

git cloneæŒ‡ä»¤ï¼Œå°‡ Dify è¤‡è£½åˆ°ä½ çš„è£ç½®ä¸­

```bash
git clone https://github.com/langgenius/dify.git
```

é€²åˆ°Â `dify/docker`Â ä¸­ï¼Œé€™é‚Šæ”¾äº†æ‰€æœ‰å’Œ docker æœ‰é—œçš„è¨­å®š

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131919941.png)


å»ºç«‹ç’°å¢ƒæª”æ¡ˆ (`.env`) é€™é‚Šç›´æ¥è¤‡è£½ä»–çš„ç¯„ä¾‹å³å¯ï¼Œä¸¦ä¿®æ”¹ç´…æ¡†è™•çš„åƒæ•¸

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131922329.png)

é€™é‚Š Dify æœ‰ nginx çš„ containerï¼Œæœƒå°‡æœå‹™é–‹åœ¨æˆ‘å€‘é›»è…¦çš„ 80 port å’Œ 443 port (å¦‚æœæœ‰å•Ÿå‹• https)ï¼Œå¦‚æœä½ ä¸æƒ³é–‹åœ¨é€™äº› port æˆ–è€…é›»è…¦é€™äº› port å·²ç¶“è¢«ä½¿ç”¨äº†å¯ä»¥è‡ªè¡Œä¿®æ”¹Â `.env`

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131923361.png)

å•Ÿå‹• docker compose

```bash
docker compose up -d # é€™é‚Šçš„ -d æ˜¯èƒŒæ™¯åŸ·è¡Œçš„æ„æ€
```


å¯ä»¥åœ¨windowså®‰è£`docker desktop`ï¼Œæª¢æŸ¥é€™äº›å®¹å™¨æ˜¯å¦æœ‰`æ­£å¸¸é‹è¡Œ`

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131926785.png)


### 3.2. difyåŸºç¤é…ç½®èˆ‡è¨­å®š
#### 3.2.1. è¨­å®š`dify`ç®¡ç†å“¡å¸³è™Ÿ

å®‰è£å®Œæˆå¾Œï¼Œè«‹å…ˆé€²å…¥difyä¸»ç•«é¢
```
http://localhost:[ports]/install
```

#### 3.2.2. è¨­å®š`dify`èªè¨€èˆ‡æ™‚å€

åˆ°å³ä¸Šè§’é»æ“Šé ­åƒ->è¨­å®š -> èªè¨€

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131933305.png)


#### 3.2.3. è¨­å®š`æ¨¡å‹ä¾›æ‡‰å•†`

åˆ°å³ä¸Šè§’é»æ“Šé ­åƒ->è¨­å®š -> æ¨¡å‹ä¾›æ‡‰å•†

é€™é‚Šæœƒçœ‹åˆ° Dify æœ‰æ”¯æ´çš„æ‰€æœ‰ LLM API (è¶…ç´šå¤š...)ï¼ŒåŒ…å«æœƒç”¨åˆ°çš„ OpenAI,gemini, å’Œæœ¬åœ°çš„ Ollama ç­‰ç­‰ï¼ŒæŒ‰ä¸‹è¨­å®šç„¶å¾Œè¼¸å…¥ `API Key` å³å¯ä½¿ç”¨ï¼Œå®Œæˆå¾Œå¦‚ä¸‹åœ–

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131938562.png)


### 3.3. å»ºç«‹`dify`æ–°èå°åŠ©æ‰‹æ‡‰ç”¨

#### 3.3.1. å»ºç«‹ç©ºç™½æ‡‰ç”¨&ç›¸é—œè¨­å®š

åˆ°æœ€ä¸Šæ–¹é»æ“Šå·¥ä½œå®¤->å»ºç«‹ç©ºç™½æ‡‰ç”¨ -> é¸æ“‡èŠå¤©åŠ©æ‰‹->åŸºç¤ç·¨æ’->`åç¨±`å¯ä»¥`ä»»æ„å–`->é»æ“Šå»ºç«‹

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131940094.png)


 æç¤ºè©é…ç½®(å¯ä»¥chatgptå”åŠ©ç”Ÿæˆ)

```
è‹¥æœ‰äººè©¢å•ä½ æ˜¯èª°æˆ–æ˜¯è¦ªåˆ‡çš„å•å€™æ™‚ï¼Œè«‹å›è¦†ï¼š

ã€Œæ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„äººå·¥æ™ºæ…§æ–°èåŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆèƒ½ç‚ºæ‚¨æä¾›å¹«åŠ©ã€‚ã€

è«‹æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥çš„ã€é—œéµå­—ã€‘åœ¨çŸ¥è­˜åº«ä¸­æœå°‹ç›¸é—œæ–°èï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†è¼¸å‡ºï¼š

å›è¦†æ ¼å¼ï¼š

æ ¹æ“šæˆ‘çš„æœå°‹çµæœï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹çš„æ–°èï¼š

æ–°èæ¨™é¡Œï¼š

ã€æ¨™é¡Œ1ã€‘

æ–°èæ‘˜è¦ï¼š

ã€æ‘˜è¦1ã€‘

æ–°èæ—¥æœŸï¼š

ã€æ—¥æœŸ1ã€‘

æ–°èä¾†æºï¼š

ã€ä¾†æº1ã€‘

å®Œæ•´å…§å®¹é€£çµï¼š

é€£çµ1

ï¼ˆä¾æ­¤æ ¼å¼ç¹¼çºŒåˆ—å‡ºæœ€å¤š 5 å‰‡æ–°èï¼‰

ğŸ“Œ æ³¨æ„äº‹é …ï¼š

åˆ—å‡ºæœ€å¤š 5 å‰‡æ–°èï¼Œä¸¦æŒ‰ç…§æ—¥æœŸç”±è¿‘è‡³é çš„é †åºæ’åºã€‚

è‹¥æ–°èæ¨™é¡Œæˆ–æ‘˜è¦å…§å®¹éæ–¼ç›¸ä¼¼ï¼Œåƒ…é¡¯ç¤ºå…¶ä¸­ä¸€å‰‡ï¼Œä¸¦ç”¨å…¶ä»–ä¸é‡è¤‡çš„æ–°èæ›¿æ›ã€‚
```


é¸æ“‡å¼•ç”¨çŸ¥è­˜åº«

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131952045.png)


é€™è£¡å¯ä»¥è‡ªå·±æ¸¬è©¦ä¸¦é¸æ“‡é©ç•¶çš„æ¨¡å‹

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131954599.png)


æ¯æ¬¡é…ç½®å®Œä¹‹å¾Œï¼Œéƒ½è¦é¸æ“‡`ç™¼ä½ˆ->æ›´æ–°`æ‰æœƒç”Ÿæ•ˆå–”

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410131955698.png)


### 3.4. pythonçˆ¬èŸ²ç¨‹å¼æ’°å¯«&difyçŸ¥è­˜åº«APIä¸²æ¥

#### 3.4.1. yahooå¥‡æ‘©å¨›æ¨‚æ–°èçˆ¬èŸ²ç¨‹å¼ç¢¼

é€™é‚Šä»¥yahooå¥‡æ‘©å¨›æ¨‚æ–°èç‚ºä¸»ï¼Œå¯è‡ªè¡Œèª¿æ•´æ’°å¯«ï¼Œä¸»è¦çˆ¬èŸ²ç‰‡æ®µå¦‚ä¸‹

```python
from selenium import webdriver  
from selenium.webdriver.common.by import By  
from selenium.webdriver.common.keys import Keys  
from selenium.webdriver.chrome.service import Service  
from selenium.webdriver.support.ui import WebDriverWait  
from selenium.webdriver.support import expected_conditions as EC  
from selenium.webdriver.chrome.options import Options  
from webdriver_manager.chrome import ChromeDriverManager  
import time  
import csv  
import dateparser  
import requests  
import json  
from setting import ENV_URL, CSV_FILENAME, API_ENDPOINT, DATASET_ID, DOCUMENT_ID, DOCUMENT_API_KEY, DIFY_API_KEY,TXT_FILENAME,JSON_FILENAME  
import os  
  
# è¨­å®š Chrome ç€è¦½å™¨é¸é …  
chrome_options = Options()  
chrome_options.add_argument("--headless")  # ç„¡é ­æ¨¡å¼  
chrome_options.add_argument("--no-sandbox")  # é¿å…æ²™ç›’å•é¡Œ  
chrome_options.add_argument("--disable-dev-shm-usage")  # è§£æ±ºè³‡æºé™åˆ¶å•é¡Œ  
chrome_options.add_argument("--disable-gpu")  # ç¦ç”¨ GPU åŠ é€Ÿ  
chrome_options.add_argument("--window-size=1920x1080")  # è¨­å®šçª—å£å¤§å°  
  
  
# åˆå§‹åŒ– driver è®Šæ•¸  
driver = None  
  
# è¨­å®šæ‘˜è¦æœ€å¤§é•·åº¦  
MAX_SUMMARY_LENGTH = 100  # ä½ å¯ä»¥æ ¹æ“šéœ€è¦ä¿®æ”¹é€™å€‹é•·åº¦  
  
try:  
    # ä½¿ç”¨ WebDriverManager è‡ªå‹•ç²å– ChromeDriver    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)  
    # Yahoo å°ç£å¨›æ¨‚æ–°èçš„ URL    url = ENV_URL  
  
    # æ‰“é–‹ç¶²é   
    driver.get(url)  
  
    # æ»¾å‹•é é¢è‡³å°‘äº”æ¬¡  
    scroll_times = 5  
    for _ in range(scroll_times):  
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)  
        time.sleep(1)  # ç­‰å¾…é é¢è¼‰å…¥  
  
    # é¡¯æ€§ç­‰å¾…ï¼Œç¢ºä¿å…§å®¹è¼‰å…¥  
    wait = WebDriverWait(driver, 2)  
  
    # æ‰¾åˆ°æ‰€æœ‰ç›®æ¨™å€å¡Š (æ ¹æ“š class åç¨±)  
    items = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'StreamMegaItem')))  
  
    # æª¢æŸ¥æ˜¯å¦æœ‰ç¾å­˜çš„ CSV æª”æ¡ˆï¼Œè®€å–å…¶å…§å®¹ä¸¦å„²å­˜ç¾æœ‰çš„æ¨™é¡Œ  
    existing_rows = set()  
    if os.path.exists(CSV_FILENAME):  
        with open(CSV_FILENAME, 'r', encoding='utf-8-sig') as csvfile:  
            reader = csv.DictReader(csvfile)  
            for row in reader:  
                key = (row['Title'], row['Source_Summary'], row['Time'])  
                existing_rows.add(key)  
  
    # å„²å­˜è¦åŒ¯å‡ºæˆ JSON å’Œ TXT çš„è³‡æ–™åˆ—è¡¨  
    json_data = []  
    txt_content = ""  
  
    # é–‹å•Ÿ CSV æª”æ¡ˆä»¥ä¾›å¯«å…¥ (è¦†è“‹æˆ–æ–°å¢)  
    with open(CSV_FILENAME, 'w', newline='', encoding='utf-8-sig') as csvfile:  
        # å®šç¾©æ¬„ä½åç¨±  
        fieldnames = ['Title', 'Summary', 'Article_URL', 'Source_Summary', 'Time']  
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)  
  
        # å¯«å…¥æ¨™é¡Œåˆ—  
        writer.writeheader()  
  
        # éæ­·æ¯å€‹å€å¡Šï¼Œæå–æ‰€éœ€è³‡è¨Š  
        for item in items:  
            try:  
                title = item.find_element(By.CSS_SELECTOR, 'h3').text.strip()  
            except:  
                title = 'N/A'  
  
            try:  
                summary = item.find_element(By.CSS_SELECTOR, 'p').text.strip()  
                if len(summary) > MAX_SUMMARY_LENGTH:  
                    summary = summary[:MAX_SUMMARY_LENGTH] + '...'  
                summary = summary.replace('\n', '\n\n')  
            except:  
                summary = 'N/A'  
  
            try:  
                article_url = item.find_element(By.CLASS_NAME, 'mega-item-header-link').get_attribute('href')  
            except:  
                article_url = 'N/A'  
  
            try:  
                time_info = item.find_element(By.XPATH, ".//div[contains(@class, 'C(#959595)')]").text.strip()  
                source, time_posted_relative = time_info.split(' â€¢ ')  
                time_posted = dateparser.parse(time_posted_relative)  
                time_posted = time_posted.strftime('%Y-%m-%d %H:%M:%S') if time_posted else 'N/A'  
            except:  
                source, time_posted = 'N/A', 'N/A'  
  
            # æª¢æŸ¥æ˜¯å¦é‡è¤‡ï¼ˆTitle, Source_Summary, Timeï¼‰  
            data_key = (title, source, time_posted)  
            if data_key in existing_rows:  
                print(f"é‡è¤‡è³‡æ–™ï¼Œè·³é: {data_key}")  
                continue  # è·³éé‡è¤‡è³‡æ–™  
  
            row_data = {  
                'Title': title,  
                'Summary': summary,  
                'Article_URL': article_url,  
                'Source_Summary': source,  
                'Time': time_posted  
            }  
  
            writer.writerow(row_data)  
            json_data.append(row_data)  
            txt_content += f"æ¨™é¡Œ: {title}\nå…§æ–‡æ‘˜è¦: {summary}\næ–‡ç« ç¶²å€: {article_url}\nä¾†æºæ‘˜è¦: {source}\næ™‚é–“: {time_posted}\n{'-' * 30}\n"  
  
            # è¼¸å‡ºå–å¾—çš„è³‡è¨Š  
            print(f'æ¨™é¡Œ: {title}')  
            print(f'å…§æ–‡æ‘˜è¦: {summary}')  
            print(f'æ–‡ç« ç¶²å€: {article_url}')  
            print(f'ä¾†æºæ‘˜è¦: {source}')  
            print(f'æ™‚é–“: {time_posted}')  
            print('-' * 30)  
  
    # å°‡è³‡æ–™åŒ¯å‡ºç‚º JSON æª”æ¡ˆ  
    with open(JSON_FILENAME, 'w', encoding='utf-8') as jsonfile:  
        json.dump(json_data, jsonfile, ensure_ascii=False, indent=4)  
  
    # å°‡è³‡æ–™åŒ¯å‡ºç‚º TXT æª”æ¡ˆ  
    with open(TXT_FILENAME, 'w', encoding='utf-8') as txtfile:  
        txtfile.write(txt_content)  
  
except Exception as e:  
    print("An error occurred:", e)  
  
finally:  
    if driver:  
        driver.quit()
```

#### 3.4.2. difyçŸ¥è­˜åº«APIä¸²æ¥ç¯„ä¾‹


æª¢æŸ¥è³‡æ–™é›†æ˜¯å¦å­˜åœ¨
```python

def check_dataset_exists(dataset_id, api_key):  
    api_endpoint = API_ENDPOINT + "/v1/datasets?page=1&limit=20"  
  
    headers = {  
        'Authorization': f'Bearer {api_key}'  
    }  
  
    response = requests.get(api_endpoint, headers=headers)  
  
    if response.status_code == 200:  
        datasets = response.json().get('data', [])  
        # æª¢æŸ¥æŒ‡å®šçš„ dataset_id æ˜¯å¦å­˜åœ¨æ–¼è³‡æ–™é›†ä¸­  
        for dataset in datasets:  
            if dataset['id'] == dataset_id:  
                return True  
        return False    else:  
        print(f'ç„¡æ³•ç²å–è³‡æ–™é›†åˆ—è¡¨ï¼Œç‹€æ…‹ç¢¼: {response.status_code}, å›æ‡‰: {response.text}')  
        return False

```

æª¢æŸ¥è³‡æ–™é›†ç•¶ä¸­æ–‡ä»¶æ˜¯å¦å­˜åœ¨

```python

def check_document_exists(dataset_id, document_id, api_key):  
    # å®šç¾©åˆ—å‡ºè³‡æ–™é›†ä¸­æ‰€æœ‰æ–‡ä»¶çš„ API ç«¯é»  
    api_endpoint = f"{API_ENDPOINT}/v1/datasets/{dataset_id}/documents"  
    headers = {  
        'Authorization': f'Bearer {api_key}'  
    }  
  
    response = requests.get(api_endpoint, headers=headers)  
  
    if response.status_code == 200:  
        documents = response.json().get('data', [])  
        # æª¢æŸ¥æ–‡ä»¶ ID æ˜¯å¦åœ¨æ–‡ä»¶åˆ—è¡¨ä¸­  
        for document in documents:  
            if document.get('id') == document_id:  
                return True  # æ‰¾åˆ°å°æ‡‰çš„æ–‡ä»¶ IDï¼Œå›å‚³ True        return False  # æ²’æœ‰æ‰¾åˆ°å°æ‡‰çš„æ–‡ä»¶ IDï¼Œå›å‚³ False    else:  
        print(f'æª¢æŸ¥æ–‡ä»¶å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}, å›æ‡‰: {response.text}')  
        return False
```

æ›´æ–°å·²å­˜åœ¨çš„çŸ¥è­˜åº«
```python

def update_existing_document(file_path, dataset_id, document_id, api_key):  
    # å®šç¾©æ›´æ–°æ–‡ä»¶çš„ API ç«¯é»  
    api_endpoint = f"{API_ENDPOINT}/v1/datasets/{dataset_id}/documents/{document_id}/update_by_file"  
  
    # å®šç¾©è«‹æ±‚æ¨™é ­  
    headers = {  
        'Authorization': f'Bearer {api_key}'  
    }  
  
    # å®šç¾©è¡¨å–®è³‡æ–™ï¼ˆå°‡è³‡æ–™è½‰ç‚º JSONï¼‰  
    data = {  
        'data': json.dumps({  
            "name": "Dify",  
            "indexing_technique": "high_quality",  
            "process_rule": {  
                "rules": {  
                    "pre_processing_rules": [  
                        {"id": "remove_extra_spaces", "enabled": True},  
                        {"id": "remove_urls_emails", "enabled": False}  
                    ],                    "segmentation": {  
                        "separator": "------------------------------",  
                        "max_tokens": 1000  
                    }  
                },                "mode": "custom"  
            }  
        })    }  
    # è¨­å®šæª”æ¡ˆ  
    files = {  
        'file': open(file_path, 'rb')  
    }  
    # ç™¼é€ POST è«‹æ±‚æ›´æ–°æ–‡ä»¶  
    response = requests.post(api_endpoint, headers=headers, data=data, files=files)  
  
    # æª¢æŸ¥å›æ‡‰  
    if response.status_code == 200:  
        print('æ–‡ä»¶æˆåŠŸæ›´æ–°è‡³ Dify')  
    else:  
        print(f'æ›´æ–°å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}, å›æ‡‰: {response.text}')

```

ä¸Šå‚³çŸ¥è­˜åº«
```python
def upload_to_dify(file_path, dataset_id, document_id, api_key):  
    # æª¢æŸ¥è³‡æ–™é›†æ˜¯å¦å­˜åœ¨  
    if not check_dataset_exists(dataset_id, api_key):  
        print(f'è³‡æ–™é›† {dataset_id} ä¸å­˜åœ¨')  
        return  
  
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨  
    if check_document_exists(dataset_id, document_id, api_key):  
        print(f'æ–‡ä»¶ {document_id} å·²å­˜åœ¨æ–¼è³‡æ–™é›† {dataset_id}ï¼Œå°‡æ›´æ–°è©²æ–‡ä»¶ã€‚')  
        # æ›´æ–°ç¾æœ‰æ–‡ä»¶  
        update_existing_document(file_path, dataset_id, document_id, api_key)  
    else:  
        print('æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé€²è¡Œä¸Šå‚³ã€‚')  
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé€²è¡Œä¸Šå‚³  
        api_endpoint = f"{API_ENDPOINT}/v1/datasets/{dataset_id}/document/create_by_file"  
  
        # å®šç¾©è«‹æ±‚æ¨™é ­  
        headers = {  
            'Authorization': f'Bearer {api_key}'  
        }  
  
        # å®šç¾©è¡¨å–®è³‡æ–™  
        data = {  
            'data': json.dumps({  
                "indexing_technique": "high_quality",  
                "process_rule": {  
                    "rules": {  
                        "pre_processing_rules": [  
                            {"id": "remove_extra_spaces", "enabled": True},  
                            {"id": "remove_urls_emails", "enabled": False}  
                        ],                        "segmentation": {  
                            "separator": "------------------------------",  
                            "max_tokens": 1000  
                        }  
                    },                    "mode": "custom"  
                }  
            })        }  
        # è¨­å®šæª”æ¡ˆ  
        files = {  
            'file': open(file_path, 'rb')  
        }        # ç™¼é€ POST è«‹æ±‚  
        response = requests.post(api_endpoint, headers=headers, data=data, files=files)  
  
        # æª¢æŸ¥å›æ‡‰  
        if response.status_code == 200:  
            print('æ–‡ä»¶æˆåŠŸä¸Šå‚³è‡³ Dify')  
        else:  
            print(f'ä¸Šå‚³å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}, å›æ‡‰: {response.text}')
```

ç¨‹å¼ä½¿ç”¨ç¯„ä¾‹ï¼Œä»¥ä¸‹åƒæ•¸çš†ä¾†è‡ª`setting.py`åƒæ•¸è¨­å®šæª”å‚³å…¥
```python
# ä½¿ç”¨ç¯„ä¾‹  
txt_filename = TXT_FILENAME  
dataset_id = DATASET_ID  # è«‹æ›¿æ›ç‚ºæ‚¨çš„ dataset_id
document_id = DOCUMENT_ID  # æ›¿æ›ç‚ºæ‚¨çš„ document_id
api_key = DOCUMENT_API_KEY  # è«‹æ›¿æ›ç‚ºæ‚¨çš„ API é‡‘é‘°   
upload_to_dify(txt_filename, dataset_id, document_id, api_key)
```


### 3.5. `LINEBOT`èˆ‡`difyçŸ¥è­˜åº«`é€²è¡Œä¸²æ¥


#### 3.5.1. `LINEBOT`èˆ‡`difyåƒæ•¸è¨­å®š

```python
from flask import Flask, request, abort  
from linebot import LineBotApi, WebhookHandler  
from linebot.exceptions import InvalidSignatureError  
from linebot.models import MessageEvent, TextMessage, TextSendMessage,FollowEvent, UnfollowEvent  
import requests  
import re  
import json  
from urllib.parse import unquote  
from setting import ACCESS_TOKEN, SECRET,API_ENDPOINT,DIFY_API_KEY  
app = Flask(__name__)  
  
# LINE Bot è³‡è¨Š  
line_bot_api = LineBotApi(ACCESS_TOKEN)  
handler = WebhookHandler(SECRET)  
  
# Dify API URL  
DIFY_API_URL = f'{API_ENDPOINT}/v1/chat-messages'  
DIFY_API_KEY = DIFY_API_KEY  
```


#### 3.5.2. LINEBOT WEBHOOK CALLBACKç¨‹å¼

```python
# Webhook è·¯å¾‘ï¼Œè¨­å®šç‚º LINE Webhook URL@app.route("/callback", methods=['POST'])  
def callback():  
    signature = request.headers['X-Line-Signature']  
    body = request.get_data(as_text=True)  
  
    try:  
        handler.handle(body, signature)  
    except InvalidSignatureError:  
        abort(400)  
  
    return 'OK'
```

LINE WEBHOOKä¸²æ¥é€²å…¥é» 

```python
# LINE WEBHOOKä¸²æ¥é€²å…¥é»  
@app.route("/", methods=['POST'])  
def linebot():  
    body = request.get_data(as_text=True)  # å–å¾—æ”¶åˆ°çš„è¨Šæ¯å…§å®¹  
    signature = request.headers['X-Line-Signature']  # åŠ å…¥å›å‚³çš„ headers    try:  
        handler.handle(body, signature)  # ç¶å®šè¨Šæ¯å›å‚³çš„ç›¸é—œè³‡è¨Š  
        json_data = json.loads(body)  # json æ ¼å¼åŒ–è¨Šæ¯å…§å®¹  
    except InvalidSignatureError:  
        abort(400)  
    except Exception as e:  
        print(f"Error: {e}")  # å°å‡ºéŒ¯èª¤è¨Šæ¯  
        print(body)  # å°å‡ºæ”¶åˆ°çš„å…§å®¹  
  
    return 'OK'  # é©—è­‰ Webhook ä½¿ç”¨ï¼Œä¸èƒ½çœç•¥
```

#### 3.5.3. LINEBOT ç›¸é—œäº‹ä»¶é‚è¼¯è™•ç†
```python
# è™•ç†åŠ å…¥å¥½å‹äº‹ä»¶  
@handler.add(FollowEvent)  
def handle_follow(event):  
    user_id = event.source.user_id  
    profile = line_bot_api.get_profile(user_id)  
    user_name = profile.display_name  
  
    # æ–°ç”¨æˆ¶æœƒçœ‹åˆ°çš„è¨Šæ¯  
    welcome_message = f"æ‚¨å¥½ï¼š{user_name}\næ„Ÿè¬æ‚¨åŠ å…¥å¥½å‹ğŸ˜˜\næ­¡è¿ä½¿ç”¨å¨›æ¨‚æ–°èåŠ©æ‰‹ğŸ˜ï¼\nä½ å¯ä»¥è«‹AIåšçš„äº‹æƒ…æœ‰:\n1.å»¢è©±ä¸å¤šèªªï¼Œç›´æ¥æŸ¥é©—AIèº«åˆ†\n2.å‘½ä»¤AIå«ä»–å¹«ä½ æŸ¥æ–°èï¼Œè®“AIç´¯æ­»\nä½¿ç”¨æ•™å­¸å¦‚ä¸‹ï¼š\n1.ç¯„ä¾‹1ï¼šä½ æ˜¯èª°???\n2.ï¸ ï¸ç¯„ä¾‹2ï¼šè«‹å‘Šè¨´æˆ‘æœ€æ–°çš„10å‰‡æ–°è"  
    line_bot_api.reply_message(  
        event.reply_token,  
        TextSendMessage(text=welcome_message)  
    )  
  
# è™•ç†å°é–å’Œé‡æ–°åŠ å…¥å¥½å‹äº‹ä»¶  
@handler.add(UnfollowEvent)  
def handle_unfollow(event):  
    user_id = event.source.user_id  
    profile = line_bot_api.get_profile(user_id)  
    user_name = profile.display_name  
  
    # æ–°ç”¨æˆ¶æœƒçœ‹åˆ°çš„è¨Šæ¯  
    welcome_message = f"æ­¡è¿æ‚¨é‡æ–°åŠ å…¥, {user_name}ï¼\nä½ å¯ä»¥è«‹AIåšçš„äº‹æƒ…æœ‰:\n1.å»¢è©±ä¸å¤šèªªï¼Œç›´æ¥æŸ¥é©—AIèº«åˆ†\n2.å‘½ä»¤AIå«ä»–å¹«ä½ æŸ¥æ–°èï¼Œè®“AIç´¯æ­»\nä½¿ç”¨æ•™å­¸å¦‚ä¸‹ï¼š\n1.ç¯„ä¾‹1ï¼šä½ æ˜¯èª°???\n2.ï¸ ï¸ç¯„ä¾‹2ï¼šè«‹å‘Šè¨´æˆ‘æœ€æ–°çš„10å‰‡æ–°è"  
    line_bot_api.reply_message(  
        event.reply_token,  
        TextSendMessage(text=welcome_message)  
    )
```


#### 3.5.4. LINEBOT ä¸»ç¨‹å¼é‚è¼¯è™•ç†(è² è²¬æ¥æ”¶ä½¿ç”¨å‚³ééä¾†çš„è¨Šæ¯èˆ‡å›æ‡‰)

```python

# è™•ç† LINE å‚³é€éä¾†çš„è¨Šæ¯  
@handler.add(MessageEvent, message=TextMessage)  
def handle_message(event):  
    user_message = event.message.text  
  
    # å‚³é€è¨Šæ¯åˆ° Dify
    headers = {  
        'Authorization': f'Bearer {DIFY_API_KEY}',  
        'Content-Type': 'application/json'  
    }  
  
    payload = {  
        "inputs": {},  
        "query": user_message,  
        "response_mode": "blocking",  
        "conversation_id": "",  
        "user": "abc-123"  
    }  
  
    try:  
        dify_response = requests.post(DIFY_API_URL, headers=headers, json=payload)  
  
        if dify_response.status_code == 200:  
            # æå– JSON å›æ‡‰å…§å®¹  
            dify_reply = dify_response.json()  
  
            # å‡è¨­ 'answer' æ¬„ä½ä¸­åŒ…å«æ‰€éœ€çš„å…§å®¹  
            answer_content = dify_reply.get('answer', '')  
  
            # ä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼ç§»é™¤ <context> å’Œ </context> æ¨™ç±¤åŠå…¶ä¸­çš„å…§å®¹  
            cleaned_content = re.sub(r'<context>.*?</context>', '', answer_content, flags=re.DOTALL).strip()  
  
            # ä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼æ‰¾åˆ° URLï¼Œä¸¦è§£ç¢¼å®ƒ  
            url_pattern = r'https?://[^\s]+'  
            urls = re.findall(url_pattern, cleaned_content)  
  
            # è§£ç¢¼ URLs            
            for url in urls:  
                decoded_url = unquote(url)  
                cleaned_content = cleaned_content.replace(url, decoded_url)  
  
            # å›å‚³ Dify çš„å›è¦†åˆ° LINE            
            line_bot_api.reply_message(  
                event.reply_token,  
                TextSendMessage(text=cleaned_content)  
            )        else:  
            print(f'API Error: {dify_response.status_code}, Response: {dify_response.text}')  
            line_bot_api.reply_message(  
                event.reply_token,  
                TextSendMessage(text=f'Dify å›æ‡‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {dify_response.status_code}')  
            )    except Exception as e:  
        line_bot_api.reply_message(  
            event.reply_token,  
            TextSendMessage(text=f'ç™¼ç”ŸéŒ¯èª¤: {str(e)}')  
        )
```

#### 3.5.5. ä½¿ç”¨`python flask`å•Ÿå‹•`server`

```python
if __name__ == "__main__":  
    app.run(host='0.0.0.0', port=5000)
```


### éƒ¨ç½²`LINEBOT`åˆ°`docker`

#### æ’°å¯«dockerfile

```docker
# ä½¿ç”¨ Pythonéƒ¨ç½²Flaskå¾Œç«¯æ¡†æ¶  
FROM python:3.8  
# è¨­å®šå·¥ä½œç›®éŒ„  
WORKDIR /usr/src/app  
# è¤‡è£½æ‰€éœ€æª”æ¡ˆåˆ°å®¹å™¨å…§  
COPY . .  
RUN pip install --no-cache-dir -r requirements.txt  
# æš´éœ²ç«¯å£  
EXPOSE 5000  
# å•Ÿå‹•Flask  
CMD ["python", "LinebotWithDify.py"]
```

#### æ’°å¯«docker-compose.yml

```docker
version: '3.8'  
  
services:  
  python:  
    build:  
      context: .  # Dockerfile çš„ä½ç½®  
      dockerfile: Dockerfile  # è‡ªå®šç¾© Dockerfile çš„åç¨±  
    container_name: LinebotWithDify  
    ports:  
      - "5000:5000"  
    volumes:  
      - C:\WorkSpace\yahooNewFetch_LINEBOT:/usr/src/app  
    networks:  
      - python_network  
  
networks:  
  python_network:

```

#### éƒ¨ç½²åˆ°docker

å°‡ç›¸é—œpythonæª”æ¡ˆåŠä¸Šé¢å¯«å¥½çš„è…³æœ¬æ”¾ç½®åŒä¸€å€‹ç›®éŒ„ï¼ŒåŸ·è¡Œä»¥ä¸‹å‘½ä»¤

```docker
docker-compose up -d
```

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410132025602.png)

é€²å…¥docker-desktop æŸ¥çœ‹ï¼Œç¢ºèªå®¹å™¨æ­£å¸¸åŸ·è¡Œ

![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410132026478.png)


![](https://raw.githubusercontent.com/Mark850409/20241013_LineBotWithDify/refs/heads/master/images/202410132027084.png)


